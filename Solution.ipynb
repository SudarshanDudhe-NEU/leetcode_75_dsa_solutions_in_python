{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2868bdd",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99032d1-1d21-44ca-83b1-d967bf3e49d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level-order representations:\n",
      "Tree 1: [1, 2, 3, None, 5, None, 4]\n",
      "Tree 2: [1, 2, 3, 4, None, None, None, 5]\n",
      "Tree 3: [1, None, 3]\n",
      "Tree 4: Empty tree\n",
      "\n",
      "Inorder traversals:\n",
      "Tree 1: 2 5 1 3 4\n",
      "Tree 2: 5 4 2 1 3\n",
      "Tree 3: 1 3\n",
      "Tree 4: \n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, List\n",
    "from collections import deque\n",
    "\n",
    "# Definition for a binary tree node.\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self, val=0, left=None, right=None):\n",
    "        self.val = val\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "\n",
    "def create_tree_from_level_order(data: List[Optional[int]]) -> Optional[TreeNode]:\n",
    "    \"\"\"\n",
    "    Create a binary tree from level-order array representation.\n",
    "    None values in the array represent empty nodes.\n",
    "    \n",
    "    Args:\n",
    "        data: List of integers or None values in level-order sequence\n",
    "        \n",
    "    Returns:\n",
    "        Root node of the created tree, or None if input is empty\n",
    "    \"\"\"\n",
    "    if not data or data[0] is None:\n",
    "        return None\n",
    "\n",
    "    root = TreeNode(data[0])  # Root node\n",
    "    queue = deque([root])     # Queue for level-order insertion\n",
    "    index = 1                 # Index in the data list\n",
    "\n",
    "    while queue and index < len(data):\n",
    "        node = queue.popleft()  # Get the current node\n",
    "\n",
    "        # Assign the left child if available\n",
    "        if index < len(data):\n",
    "            if data[index] is not None:\n",
    "                node.left = TreeNode(data[index])\n",
    "                queue.append(node.left)\n",
    "            index += 1\n",
    "\n",
    "        # Assign the right child if available\n",
    "        if index < len(data):\n",
    "            if data[index] is not None:\n",
    "                node.right = TreeNode(data[index])\n",
    "                queue.append(node.right)\n",
    "            index += 1\n",
    "\n",
    "    return root\n",
    "\n",
    "\n",
    "def print_tree_level_order(root: Optional[TreeNode]) -> None:\n",
    "    \"\"\"\n",
    "    Print the level-order representation of a tree (breadth-first).\n",
    "    \n",
    "    Args:\n",
    "        root: Root node of the binary tree\n",
    "    \"\"\"\n",
    "    if not root:\n",
    "        print(\"Empty tree\")\n",
    "        return\n",
    "\n",
    "    queue = deque([root])\n",
    "    result = []\n",
    "\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        if node:\n",
    "            result.append(str(node.val))\n",
    "            queue.append(node.left)\n",
    "            queue.append(node.right)\n",
    "        else:\n",
    "            result.append(\"None\")\n",
    "\n",
    "    # Remove trailing None values\n",
    "    while result and result[-1] == \"None\":\n",
    "        result.pop()\n",
    "\n",
    "    print(\"[\" + \", \".join(result) + \"]\")\n",
    "\n",
    "\n",
    "def inorder_traversal(root: Optional[TreeNode]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Perform an inorder traversal of the binary tree.\n",
    "    \n",
    "    Args:\n",
    "        root: Root node of the binary tree\n",
    "        \n",
    "    Returns:\n",
    "        List of values in inorder sequence\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    def traverse(node):\n",
    "        if node:\n",
    "            traverse(node.left)\n",
    "            result.append(node.val)\n",
    "            traverse(node.right)\n",
    "\n",
    "    traverse(root)\n",
    "    return result\n",
    "\n",
    "\n",
    "def print_inorder_traversal(root: Optional[TreeNode]) -> None:\n",
    "    \"\"\"\n",
    "    Print an inorder traversal of the binary tree.\n",
    "    \n",
    "    Args:\n",
    "        root: Root node of the binary tree\n",
    "    \"\"\"\n",
    "    values = inorder_traversal(root)\n",
    "    print(\" \".join(map(str, values)))\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Level-order representations from the markdown examples\n",
    "    data1 = [1, 2, 3, None, 5, None, 4]\n",
    "    data2 = [1, 2, 3, 4, None, None, None, 5]\n",
    "    data3 = [1, None, 3]\n",
    "    data4 = []\n",
    "\n",
    "    # Create the trees\n",
    "    tree1 = create_tree_from_level_order(data1)\n",
    "    tree2 = create_tree_from_level_order(data2)\n",
    "    tree3 = create_tree_from_level_order(data3)\n",
    "    tree4 = create_tree_from_level_order(data4)\n",
    "\n",
    "    # Print level-order representation\n",
    "    print(\"Level-order representations:\")\n",
    "    print(\"Tree 1:\", end=\" \")\n",
    "    print_tree_level_order(tree1)\n",
    "    print(\"Tree 2:\", end=\" \")\n",
    "    print_tree_level_order(tree2)\n",
    "    print(\"Tree 3:\", end=\" \")\n",
    "    print_tree_level_order(tree3)\n",
    "    print(\"Tree 4:\", end=\" \")\n",
    "    print_tree_level_order(tree4)\n",
    "\n",
    "    # Print inorder traversals\n",
    "    print(\"\\nInorder traversals:\")\n",
    "    print(\"Tree 1:\", end=\" \")\n",
    "    print_inorder_traversal(tree1)\n",
    "    print(\"Tree 2:\", end=\" \")\n",
    "    print_inorder_traversal(tree2)\n",
    "    print(\"Tree 3:\", end=\" \")\n",
    "    print_inorder_traversal(tree3)\n",
    "    print(\"Tree 4:\", end=\" \")\n",
    "    print_inorder_traversal(tree4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ff64a-3821-4522-a195-abb1598f1445",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8afb3435-2256-4dc5-936d-eb79a0f1a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    def rightSideView(self, root: Optional[TreeNode]) -> List[int]:\n",
    "        if not root:\n",
    "            return []\n",
    "        queue = deque([root])\n",
    "        result = []\n",
    "        while queue:\n",
    "            level_size = len(queue)\n",
    "            current_level = []\n",
    "            for _ in range(level_size):\n",
    "                node = queue.popleft()\n",
    "                current_level.append(node.val)\n",
    "                if node.left:\n",
    "                    queue.append(node.left)\n",
    "                if node.right:\n",
    "                    queue.append(node.right)\n",
    "            result.append(current_level[-1])\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be42d66c-0fef-4a6a-b202-2f11aaab7e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4]\n",
      "[1, 3, 4, 5]\n",
      "[1, 3]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "s = Solution()\n",
    "print(s.rightSideView(tree1))  # [1, 3, 4]  # 1, 3, 4\n",
    "print(s.rightSideView(tree2))  # [1, 3, 5]  # 1, 3, 4, 5\n",
    "print(s.rightSideView(tree3))  # [1, 3]  # 1, 3\n",
    "print(s.rightSideView(tree4))  # []  # []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f6269b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS Traversal: [1, 2, 3, 5, 4]\n",
      "BFS Traversal: [1, 2, 3, 4, 5]\n",
      "BFS Traversal: [1, 3]\n",
      "BFS Traversal: []\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "# TreeNode class definition (same as before)\n",
    "class TreeNode:\n",
    "    def __init__(self, val=0, left=None, right=None):\n",
    "        self.val = val\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "\n",
    "def bfs(root):\n",
    "    if not root:\n",
    "        return []\n",
    "\n",
    "    queue = deque([root])  # Start with the root node in the queue\n",
    "    result = []  # To store the BFS traversal order\n",
    "\n",
    "    while queue:\n",
    "        node = queue.popleft()  # Dequeue the front node\n",
    "        # Visit the node (here we just store the value)\n",
    "        result.append(node.val)\n",
    "\n",
    "        # Enqueue the left and right children (if they exist)\n",
    "        if node.left:\n",
    "            queue.append(node.left)\n",
    "        if node.right:\n",
    "            queue.append(node.right)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Perform BFS traversal\n",
    "bfs_result = bfs(tree1)\n",
    "print(\"BFS Traversal:\", bfs_result)\n",
    "\n",
    "bsf_result = bfs(tree2)\n",
    "print(\"BFS Traversal:\", bsf_result)\n",
    "\n",
    "bsf_result = bfs(tree3)\n",
    "print(\"BFS Traversal:\", bsf_result)\n",
    "\n",
    "bsf_result = bfs(tree4)\n",
    "print(\"BFS Traversal:\", bsf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "957a3412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Chat with the AI Assistant (type 'exit' to quit)\n",
      "==================================================\n",
      "\n",
      "\n",
      "Bot: How can I assist you today? Are you working on a specific project or do you have a problem you'd like help solving?\n",
      "\n",
      "\n",
      "Bot: Goodbye! ðŸ‘‹\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def query_ollama_stream(prompt, system_prompt=None, model=\"llama3.2\"):\n",
    "    \"\"\"Query the local Ollama API with streaming response\"\"\"\n",
    "    url = \"http://localhost:11434/api/chat\"\n",
    "    \n",
    "    if system_prompt:\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"stream\": True\n",
    "        }\n",
    "    else:\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"stream\": True\n",
    "        }\n",
    "    \n",
    "    full_response = \"\"\n",
    "    with requests.post(url, json=payload, stream=True) as response:\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                json_line = json.loads(line)\n",
    "                if \"message\" in json_line and \"content\" in json_line[\"message\"]:\n",
    "                    chunk = json_line[\"message\"][\"content\"]\n",
    "                    full_response += chunk\n",
    "                    print(chunk, end=\"\", flush=True)\n",
    "    \n",
    "    print()  # Add newline at the end\n",
    "    return full_response\n",
    "\n",
    "def query_ollama(prompt, system_prompt=None, model=\"llama3.2\"):\n",
    "    \"\"\"Query the local Ollama API directly\"\"\"\n",
    "    url = \"http://localhost:11434/api/chat\"\n",
    "    \n",
    "    if system_prompt:\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"stream\": False\n",
    "        }\n",
    "    else:\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"stream\": False\n",
    "        }\n",
    "    \n",
    "    response = requests.post(url, json=payload)\n",
    "    response_json = response.json()\n",
    "    \n",
    "    if \"message\" in response_json and \"content\" in response_json[\"message\"]:\n",
    "        return response_json[\"message\"][\"content\"]\n",
    "    \n",
    "    return str(response_json)\n",
    "\n",
    "def chat_bot():\n",
    "    \"\"\"Interactive chat bot interface with command support\"\"\"\n",
    "    print(\"ðŸ¤– Chat with the AI Assistant (type 'exit' to quit)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Default system prompt\n",
    "    system_prompt = \"You are a Python expert specializing in algorithm implementation.\"\n",
    "    use_streaming = False\n",
    "    \n",
    "    while True:\n",
    "        print()  # Add space for readability\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        # Handle special commands\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"\\nBot: Goodbye! ðŸ‘‹\")\n",
    "            break\n",
    "        elif user_input.lower().startswith(\"/system \"):\n",
    "            system_prompt = user_input[8:].strip()\n",
    "            print(f\"\\nBot: System prompt updated to: \\\"{system_prompt}\\\"\")\n",
    "            continue\n",
    "        elif user_input.lower() == \"/stream on\":\n",
    "            use_streaming = True\n",
    "            print(\"\\nBot: Streaming mode activated\")\n",
    "            continue\n",
    "        elif user_input.lower() == \"/stream off\":\n",
    "            use_streaming = False\n",
    "            print(\"\\nBot: Streaming mode deactivated\")\n",
    "            continue\n",
    "        elif user_input.lower() == \"/help\":\n",
    "            print(\"\\nBot: Available commands:\")\n",
    "            print(\"  - exit, quit, bye: Exit the chat\")\n",
    "            print(\"  - /system [prompt]: Change the system prompt\")\n",
    "            print(\"  - /stream on|off: Toggle streaming mode\")\n",
    "            print(\"  - /help: Show this help message\")\n",
    "            continue\n",
    "            \n",
    "        print(\"\\nBot:\", end=\" \")\n",
    "        try:\n",
    "            if use_streaming:\n",
    "                query_ollama_stream(user_input, system_prompt)\n",
    "            else:\n",
    "                response = query_ollama(user_input, system_prompt)\n",
    "                print(response)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: Could not get response from Ollama. {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chat_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a239f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 09:32:31,486 - ERROR - Main process error: 'Description'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Description'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Description'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 161\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 161\u001b[0m     main()\n",
      "Cell \u001b[0;32mIn[2], line 135\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m     start_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Process remaining items\u001b[39;00m\n\u001b[1;32m    133\u001b[0m remaining_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    134\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[start_idx:],\n\u001b[0;32m--> 135\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[start_idx:]\n\u001b[1;32m    136\u001b[0m ))\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_items:\n\u001b[1;32m    139\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(remaining_items)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m remaining items...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Description'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('fragrance_analysis.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_checkpoint(checkpoint_file):\n",
    "    \"\"\"Load previously processed results from checkpoint\"\"\"\n",
    "    if os.path.exists(checkpoint_file):\n",
    "        try:\n",
    "            with open(checkpoint_file, 'r') as f:\n",
    "                return json.load(f), True\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Could not load checkpoint: {e}\")\n",
    "    return [], False\n",
    "\n",
    "def save_checkpoint(data, checkpoint_file):\n",
    "    \"\"\"Save current progress to checkpoint file\"\"\"\n",
    "    try:\n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            json.dump(data, f)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save checkpoint: {e}\")\n",
    "        return False\n",
    "\n",
    "def query_ollama(prompt, system_prompt=None, model=\"llama2\"):\n",
    "    \"\"\"Query the local Ollama API directly\"\"\"\n",
    "    url = \"http://localhost:11434/api/chat\"\n",
    "    \n",
    "    if system_prompt:\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"stream\": False\n",
    "        }\n",
    "    else:\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"stream\": False\n",
    "        }\n",
    "    \n",
    "    response = requests.post(url, json=payload)\n",
    "    response_json = response.json()\n",
    "    \n",
    "    if \"message\" in response_json and \"content\" in response_json[\"message\"]:\n",
    "        return response_json[\"message\"][\"content\"]\n",
    "    \n",
    "    return str(response_json)\n",
    "\n",
    "def analyze_fragrance_notes(row_data):\n",
    "    \"\"\"Use Ollama to analyze and extract fragrance notes using all available context\"\"\"\n",
    "    try:\n",
    "        # Create comprehensive context from available columns\n",
    "        prompt = f\"\"\"\n",
    "        Analyze this fragrance product:\n",
    "        Name: {row_data['Product Name']}\n",
    "        Brand: {row_data['Desc.']}\n",
    "        Category: {row_data['Category']} ({row_data['Category Group']})\n",
    "        Size: {row_data['Size']}\n",
    "        \n",
    "        Classify the fragrance notes into:\n",
    "        1. Top Notes\n",
    "        2. Middle Notes (Heart Notes)\n",
    "        3. Base Notes\n",
    "        \n",
    "        Reply in strict JSON format only:\n",
    "        {{\"top_notes\": \"notes\", \"middle_notes\": \"notes\", \"base_notes\": \"notes\"}}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = query_ollama(\n",
    "            prompt,\n",
    "            system_prompt=\"You are a perfumery expert. Provide fragrance analysis in JSON format.\",\n",
    "            model=\"llama2\"\n",
    "        )\n",
    "        return json.loads(response.strip())\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"JSON parsing error: {e}\")\n",
    "        return {\n",
    "            \"top_notes\": \"Error\",\n",
    "            \"middle_notes\": \"Error\",\n",
    "            \"base_notes\": \"Error\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Analysis error: {e}\")\n",
    "        return {\n",
    "            \"top_notes\": \"Error\",\n",
    "            \"middle_notes\": \"Error\",\n",
    "            \"base_notes\": \"Error\"\n",
    "        }\n",
    "\n",
    "def process_batch(df_batch, max_workers=3):\n",
    "    \"\"\"Process a batch of items in parallel with proper throttling\"\"\"\n",
    "    results = []\n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all rows for processing\n",
    "        future_to_idx = {\n",
    "            executor.submit(analyze_fragrance_notes, row): idx \n",
    "            for idx, row in df_batch.iterrows()\n",
    "        }\n",
    "        \n",
    "        # Process completed futures with progress bar\n",
    "        with tqdm(total=len(future_to_idx), desc=\"Processing items\") as pbar:\n",
    "            for future in as_completed(future_to_idx):\n",
    "                idx = future_to_idx[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    results.append((idx, result))\n",
    "                    \n",
    "                    if result['top_notes'] != 'Error':\n",
    "                        processed_count += 1\n",
    "                    else:\n",
    "                        error_count += 1\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    error_count += 1\n",
    "                    logging.error(f\"Failed to process row {idx}: {str(e)}\")\n",
    "                    results.append((idx, {\n",
    "                        \"top_notes\": \"Error\",\n",
    "                        \"middle_notes\": \"Error\",\n",
    "                        \"base_notes\": \"Error\"\n",
    "                    }))\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "                    pbar.set_postfix({\n",
    "                        'processed': processed_count,\n",
    "                        'errors': error_count\n",
    "                    })\n",
    "                    \n",
    "                    # Add delay between requests to avoid overwhelming Ollama\n",
    "                    time.sleep(1)\n",
    "    \n",
    "    logging.info(f\"Batch complete - Successfully processed: {processed_count}, Errors: {error_count}\")\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    input_file = '/Users/sudarshan/Downloads/Grouped_Inventory_by_Category.csv'\n",
    "    output_file = '/Users/sudarshan/Downloads/Inventory_with_FragranceNotes.csv'\n",
    "    checkpoint_file = '/Users/sudarshan/Downloads/fragrance_notes_checkpoint.json'\n",
    "    batch_size = 5  # Smaller batch size for better control\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        df = pd.read_csv(input_file)\n",
    "        logging.info(f\"Loaded CSV with {len(df)} rows and columns: {df.columns.tolist()}\")\n",
    "        \n",
    "        # Verify required columns exist\n",
    "        required_columns = ['Product Name', 'Desc.', 'Category', 'Category Group', 'Size']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "            \n",
    "        # Check for existing results and create output columns if needed\n",
    "        if not all(col in df.columns for col in ['Top_Notes', 'Middle_Notes', 'Base_Notes']):\n",
    "            df['Top_Notes'] = None\n",
    "            df['Middle_Notes'] = None\n",
    "            df['Base_Notes'] = None\n",
    "            \n",
    "        # Identify rows that need processing (where notes are missing)\n",
    "        to_process = df[df['Top_Notes'].isna()].index.tolist()\n",
    "        \n",
    "        if not to_process:\n",
    "            logging.info(\"All rows already processed. Nothing to do.\")\n",
    "            return\n",
    "            \n",
    "        logging.info(f\"Need to process {len(to_process)} items\")\n",
    "        \n",
    "        # Process in batches\n",
    "        for i in range(0, len(to_process), batch_size):\n",
    "            batch_indices = to_process[i:i+batch_size]\n",
    "            batch_df = df.loc[batch_indices]\n",
    "            \n",
    "            logging.info(f\"Processing batch {i//batch_size + 1}/{(len(to_process) + batch_size - 1)//batch_size}\")\n",
    "            batch_results = process_batch(batch_df)\n",
    "            \n",
    "            # Update DataFrame with results\n",
    "            for idx, result in batch_results:\n",
    "                df.loc[idx, 'Top_Notes'] = result['top_notes']\n",
    "                df.loc[idx, 'Middle_Notes'] = result['middle_notes']\n",
    "                df.loc[idx, 'Base_Notes'] = result['base_notes']\n",
    "            \n",
    "            # Save progress after each batch\n",
    "            df.to_csv(output_file, index=False)\n",
    "            logging.info(f\"Saved progress: {i + len(batch_indices)}/{len(to_process)} items processed\")\n",
    "        \n",
    "        # Display final statistics\n",
    "        success_count = len(df[df['Top_Notes'] != 'Error'].dropna())\n",
    "        error_count = len(df[df['Top_Notes'] == 'Error'])\n",
    "        not_processed = df['Top_Notes'].isna().sum()\n",
    "        \n",
    "        logging.info(f\"\\nFinal Statistics:\\n- Successful: {success_count}\\n- Errors: {error_count}\\n- Not processed: {not_processed}\")\n",
    "        print(f\"\\nProcessing complete!\\nResults saved to: {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Main process error: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe3a3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Barcode</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Desc.</th>\n",
       "      <th>Size</th>\n",
       "      <th>Color</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Category Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1608</td>\n",
       "      <td>36494</td>\n",
       "      <td>MENS</td>\n",
       "      <td>7.25766E+11</td>\n",
       "      <td>ZEST VETIVER</td>\n",
       "      <td>MICHAEL MALUL</td>\n",
       "      <td>3.4OZ</td>\n",
       "      <td>GRN</td>\n",
       "      <td>6</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1253</td>\n",
       "      <td>7083</td>\n",
       "      <td>MENS</td>\n",
       "      <td>3.3489E+12</td>\n",
       "      <td>SAUVAGE</td>\n",
       "      <td>DIOR</td>\n",
       "      <td>3.4oz</td>\n",
       "      <td>BLK</td>\n",
       "      <td>1</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1252</td>\n",
       "      <td>12304</td>\n",
       "      <td>MENS</td>\n",
       "      <td>3.3489E+12</td>\n",
       "      <td>SAUVAGE</td>\n",
       "      <td>DIOR</td>\n",
       "      <td>2.0oz EDP</td>\n",
       "      <td>BLK</td>\n",
       "      <td>2</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>471</td>\n",
       "      <td>7029</td>\n",
       "      <td>MENS</td>\n",
       "      <td>3.27487E+12</td>\n",
       "      <td>GENTLEMEN ONLY</td>\n",
       "      <td>GIVENCHY</td>\n",
       "      <td>3.3oz</td>\n",
       "      <td>GRY</td>\n",
       "      <td>1</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1248</td>\n",
       "      <td>12358</td>\n",
       "      <td>MENS</td>\n",
       "      <td>8.42185E+11</td>\n",
       "      <td>SANTAL 33</td>\n",
       "      <td>LE LABO</td>\n",
       "      <td>3.4oz EDP</td>\n",
       "      <td>BRN</td>\n",
       "      <td>1</td>\n",
       "      <td>Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>431</td>\n",
       "      <td>2260</td>\n",
       "      <td>LADIES</td>\n",
       "      <td>6.08941E+11</td>\n",
       "      <td>FANCY LOVE BY J.S  (L) 3.4oz</td>\n",
       "      <td>JESSICA SIM</td>\n",
       "      <td>100ML</td>\n",
       "      <td>WHT</td>\n",
       "      <td>1</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>736</td>\n",
       "      <td>3596</td>\n",
       "      <td>LADIES</td>\n",
       "      <td>5.05046E+12</td>\n",
       "      <td>LIVE BY J.LO LUXE(L) EDT 3.4oz</td>\n",
       "      <td>JLO</td>\n",
       "      <td>3.4oz</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>3</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1291</td>\n",
       "      <td>5321</td>\n",
       "      <td>LADIES</td>\n",
       "      <td>5.05046E+12</td>\n",
       "      <td>STILL BY J.LO (L) SET 3.3oz</td>\n",
       "      <td>JLO</td>\n",
       "      <td>3.4oz SET</td>\n",
       "      <td>BEACH</td>\n",
       "      <td>1</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>402</td>\n",
       "      <td>1985</td>\n",
       "      <td>LADIES</td>\n",
       "      <td>3.61427E+12</td>\n",
       "      <td>EMPORIO ARMANI (L) EDP 3.3oz</td>\n",
       "      <td>ARMANI</td>\n",
       "      <td>3.4oz</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>3</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>463</td>\n",
       "      <td>11659</td>\n",
       "      <td>LADIES</td>\n",
       "      <td>4.00471E+12</td>\n",
       "      <td>GABRIELA SABATINI OLD PACK</td>\n",
       "      <td>MUELHENS</td>\n",
       "      <td>1.0oz</td>\n",
       "      <td>PURP</td>\n",
       "      <td>1</td>\n",
       "      <td>Women</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1609 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0     ID Category      Barcode                    Product Name  \\\n",
       "0           1608  36494     MENS  7.25766E+11                    ZEST VETIVER   \n",
       "1           1253   7083     MENS   3.3489E+12                         SAUVAGE   \n",
       "2           1252  12304     MENS   3.3489E+12                        SAUVAGE    \n",
       "3            471   7029     MENS  3.27487E+12                  GENTLEMEN ONLY   \n",
       "4           1248  12358     MENS  8.42185E+11                       SANTAL 33   \n",
       "...          ...    ...      ...          ...                             ...   \n",
       "1604         431   2260   LADIES  6.08941E+11    FANCY LOVE BY J.S  (L) 3.4oz   \n",
       "1605         736   3596   LADIES  5.05046E+12  LIVE BY J.LO LUXE(L) EDT 3.4oz   \n",
       "1606        1291   5321   LADIES  5.05046E+12     STILL BY J.LO (L) SET 3.3oz   \n",
       "1607         402   1985   LADIES  3.61427E+12    EMPORIO ARMANI (L) EDP 3.3oz   \n",
       "1608         463  11659   LADIES  4.00471E+12      GABRIELA SABATINI OLD PACK   \n",
       "\n",
       "              Desc.       Size  Color  Quantity Category Group  \n",
       "0     MICHAEL MALUL      3.4OZ    GRN         6            Men  \n",
       "1              DIOR      3.4oz    BLK         1            Men  \n",
       "2              DIOR  2.0oz EDP    BLK         2            Men  \n",
       "3          GIVENCHY      3.3oz    GRY         1            Men  \n",
       "4           LE LABO  3.4oz EDP    BRN         1            Men  \n",
       "...             ...        ...    ...       ...            ...  \n",
       "1604    JESSICA SIM      100ML    WHT         1          Women  \n",
       "1605            JLO      3.4oz  GREEN         3          Women  \n",
       "1606            JLO  3.4oz SET  BEACH         1          Women  \n",
       "1607         ARMANI      3.4oz   GOLD         3          Women  \n",
       "1608       MUELHENS      1.0oz   PURP         1          Women  \n",
       "\n",
       "[1609 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = '/Users/sudarshan/Downloads/Grouped_Inventory_by_Category.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6771028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
